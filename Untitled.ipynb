{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'vào đây 1 lần rồi thích mê chỗ này vì phong cách phục vụ kiểu alice đúng như tên wuan. Đồ ăn đến thức uống đều ngon giá hợp túi tiền sanh viên.thich nhất mấy món kem và soda, đồ ăn món nào cũng ok  mì spagetti  2 ly cream ngon thần thánh của mềnh   cơm gà chiên giòn  cơm cuộn ăn đỡ ngán vì có sốt cà chua, gà bên trong hơi ít'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from processor import VLSP_2018_QA_M_Processor\n",
    "import tokenization\n",
    "from modeling import BertConfig, BertForSequenceClassification\n",
    "from text_pre_processing.text_pre_processing import TextPreProcessing\n",
    "from tqdm import tqdm, trange\n",
    "import run_classifier_TABSA\n",
    "from text_pre_processing.method.qam import QA_M\n",
    "from processor import InputExample\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self, input_ids, input_mask, segment_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "\n",
    "class Predictor(object):\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(42)\n",
    "        self.bert_config = BertConfig.from_json_file('/Users/vinhtruongtrong/Downloads/drive-download-20201015T092207Z-001/bert_config.json')\n",
    "        self.processor = VLSP_2018_QA_M_Processor()\n",
    "        self.label_list = self.processor.get_labels()\n",
    "        self.tokenizer = tokenization.FullTokenizer(\n",
    "            vocab_file='/Users/vinhtruongtrong/Downloads/drive-download-20201015T092207Z-001/vocab.txt', do_lower_case=False)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        self.model = BertForSequenceClassification(self.bert_config, len(self.label_list))\n",
    "        self.model.load_state_dict(torch.load('/Users/vinhtruongtrong/Downloads/drive-download-20201015T092207Z-001/model.bin', map_location='cpu'))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def generate_QA_M(self, val, domain):\n",
    "        result = []\n",
    "        for aspect in QA_M(domain).aspect_categories:\n",
    "            question = 'bạn nghĩ thế_nào về '+ QA_M(domain).aspect_categories[aspect] + ' ?'\n",
    "            result.append([question, val])\n",
    "        return result\n",
    "    \n",
    "    def create_examples(self, lines, set_type = 'test'):\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = tokenization.convert_to_unicode(str(line[1]))\n",
    "            text_b = tokenization.convert_to_unicode(str(line[0]))\n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "                print(\"guid=\",guid)\n",
    "                print(\"text_a=\",text_a)\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b))\n",
    "        return examples\n",
    "    def convert_examples_to_features(self, examples, max_seq_length, tokenizer):\n",
    "    \n",
    "        features = []\n",
    "        for (ex_index, example) in enumerate(tqdm(examples)):\n",
    "            tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "            tokens_b = None\n",
    "            if example.text_b:\n",
    "                tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "            if tokens_b:\n",
    "                self._truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "            else:\n",
    "                if len(tokens_a) > max_seq_length - 2:\n",
    "                    tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "            tokens = []\n",
    "            segment_ids = []\n",
    "            tokens.append(\"[CLS]\")\n",
    "            segment_ids.append(0)\n",
    "            for token in tokens_a:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(0)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(0)\n",
    "\n",
    "            if tokens_b:\n",
    "                for token in tokens_b:\n",
    "                    tokens.append(token)\n",
    "                    segment_ids.append(1)\n",
    "                tokens.append(\"[SEP]\")\n",
    "                segment_ids.append(1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            while len(input_ids) < max_seq_length:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "                segment_ids.append(0)\n",
    "\n",
    "            features.append(\n",
    "                    InputFeatures(\n",
    "                            input_ids=input_ids,\n",
    "                            input_mask=input_mask,\n",
    "                            segment_ids=segment_ids))\n",
    "        return features\n",
    "\n",
    "\n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "    \n",
    "    def create_sample(self, sentence, domain = 'restaurant', method = 'QA_M'):\n",
    "        text_processing = TextPreProcessing()\n",
    "        sentence = text_processing.sentence_pre_processing(sentence)\n",
    "        auxilary_sentences = self.generate_QA_M(sentence, domain) if method == 'QA_M' else None\n",
    "\n",
    "        test_examples = self.create_examples(auxilary_sentences)\n",
    "        test_features = self.convert_examples_to_features(test_examples, 128, self.tokenizer)\n",
    "\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "\n",
    "        test_data = run_classifier_TABSA.TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "        test_dataloader = run_classifier_TABSA.DataLoader(test_data,batch_size=len(test_features), shuffle=False)\n",
    "\n",
    "        return test_dataloader\n",
    "    \n",
    "    def predict(self, sentence, domain = 'restaurant', method = 'QA_M'): \n",
    "        test_dataloader = self.create_sample(sentence, domain, method)\n",
    "        self.model.eval()\n",
    "        ouputs = None\n",
    "        for input_ids, input_mask, segment_ids in test_dataloader:\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            input_mask = input_mask.to(self.device)\n",
    "            segment_ids = segment_ids.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "            logits = F.softmax(logits, dim=-1)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            outputs = np.argmax(logits, axis=1)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def multiple_output_post_processing(self, outputs):\n",
    "        result = []\n",
    "        aspect_categories = QA_M('restaurant').aspect_categories\n",
    "        for (index, value) in enumerate(aspect_categories):\n",
    "            if(outputs[index] != 3):\n",
    "                result.append([aspect_categories[value], self.label_list[outputs[index]]])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 858.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "guid= test-0\n",
      "text_a= vào đây lần rồi thích mê chỗ này vì phong_cách phục_vụ kiểu alice đúng như tên wuan . Đồ_ăn đến thức_uống đều ngon giá hợp túi_tiền sanh viên . thich nhất mấy món kem và soda đồ ăn món nào cũng ok mì sản_phẩm ageti ly cream ngon thần_thánh của mềnh cơm gà chiên giòn cơm cuộn ăn đỡ ngán vì có sốt cà_chua gà bên trong hơi ít\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = predictor.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['phong_cách đồ_ăn', 'tích_cực'],\n",
       " ['chất_lượng đồ_ăn', 'tích_cực'],\n",
       " ['dịch_vụ', 'tích_cực'],\n",
       " ['giá thức_ăn', 'tích_cực']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.multiple_output_post_processing(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
